{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T12:57:56.721076Z",
     "start_time": "2024-07-11T12:57:37.663637Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8x-pose.pt')  # load a pretrained model\n",
    "\n",
    "# Prompt user for the video name\n",
    "video_name = input(\"Введите название видео (без расширения .mp4): \")\n",
    "\n",
    "# Construct input and output file paths\n",
    "input_path = f'./data/videos/input/{video_name}.mp4'\n",
    "output_path = f'./data/videos/output/{video_name}_output.mp4'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs('./data/videos/output/', exist_ok=True)\n",
    "\n",
    "# Predict with model on the video, specifying the output directory\n",
    "output_dir = './data/videos/output/'\n",
    "# model.predict(source=input_path, save=True, save_txt=True, save_conf=True, project=output_dir, name=video_name+'_output', show=True, conf=0.05)\n",
    "model.predict(source=input_path, save=True, save_txt=True, save_conf=True, project=output_dir, name=video_name+'_output', show=True, conf=0.2)\n",
    "\n",
    "# Find the most recent output directory\n",
    "output_dirs = sorted([d for d in os.listdir(output_dir) if os.path.isdir(os.path.join(output_dir, d))], key=lambda x: os.path.getctime(os.path.join(output_dir, x)), reverse=True)\n",
    "\n",
    "if not output_dirs:\n",
    "    print(\"Не найдена директория с результатами. Проверьте вывод YOLO.\")\n",
    "else:\n",
    "    latest_output_dir = os.path.join(output_dir, output_dirs[0])\n",
    "\n",
    "    # Find the output video file\n",
    "    output_files = [f for f in os.listdir(latest_output_dir) if f.endswith('.mp4')]\n",
    "    if not output_files:\n",
    "        print(\"Не найдено видео в результатах. Проверьте вывод YOLO.\")\n",
    "    else:\n",
    "        latest_output_file = os.path.join(latest_output_dir, output_files[0])\n",
    "\n",
    "        # Move the output file to the desired location\n",
    "        final_output_path = os.path.join(output_dir, video_name + '_output.mp4')\n",
    "        shutil.move(latest_output_file, final_output_path)\n",
    "        print(f\"Обработанное видео сохранено по пути {final_output_path}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 129.3ms\n",
      "video 1/1 (frame 2/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 42.7ms\n",
      "video 1/1 (frame 3/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 2 persons, 43.0ms\n",
      "video 1/1 (frame 4/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 39.1ms\n",
      "video 1/1 (frame 5/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 33.5ms\n",
      "video 1/1 (frame 6/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 31.8ms\n",
      "video 1/1 (frame 7/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 32.9ms\n",
      "video 1/1 (frame 8/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 29.7ms\n",
      "video 1/1 (frame 9/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 (no detections), 29.5ms\n",
      "video 1/1 (frame 10/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 34.6ms\n",
      "video 1/1 (frame 11/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 32.8ms\n",
      "video 1/1 (frame 12/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 (no detections), 29.5ms\n",
      "video 1/1 (frame 13/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 35.6ms\n",
      "video 1/1 (frame 14/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 30.6ms\n",
      "video 1/1 (frame 15/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 33.0ms\n",
      "video 1/1 (frame 16/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 32.4ms\n",
      "video 1/1 (frame 17/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 32.3ms\n",
      "video 1/1 (frame 18/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 (no detections), 32.2ms\n",
      "video 1/1 (frame 19/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 33.0ms\n",
      "video 1/1 (frame 20/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 28.9ms\n",
      "video 1/1 (frame 21/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 32.2ms\n",
      "video 1/1 (frame 22/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 32.2ms\n",
      "video 1/1 (frame 23/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 29.0ms\n",
      "video 1/1 (frame 24/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 31.5ms\n",
      "video 1/1 (frame 25/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 29.9ms\n",
      "video 1/1 (frame 26/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 1 person, 28.8ms\n",
      "video 1/1 (frame 27/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 31.1ms\n",
      "video 1/1 (frame 28/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 29.0ms\n",
      "video 1/1 (frame 29/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 30.5ms\n",
      "video 1/1 (frame 30/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 28.7ms\n",
      "video 1/1 (frame 31/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 29.5ms\n",
      "video 1/1 (frame 32/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 29.2ms\n",
      "video 1/1 (frame 33/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 28.0ms\n",
      "video 1/1 (frame 34/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 30.5ms\n",
      "video 1/1 (frame 35/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 29.3ms\n",
      "video 1/1 (frame 36/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 29.0ms\n",
      "video 1/1 (frame 37/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 5 persons, 28.5ms\n",
      "video 1/1 (frame 38/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 4 persons, 27.2ms\n",
      "video 1/1 (frame 39/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 5 persons, 29.5ms\n",
      "video 1/1 (frame 40/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 5 persons, 28.6ms\n",
      "video 1/1 (frame 41/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 4 persons, 29.3ms\n",
      "video 1/1 (frame 42/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 5 persons, 29.3ms\n",
      "video 1/1 (frame 43/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 4 persons, 29.7ms\n",
      "video 1/1 (frame 44/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 5 persons, 28.2ms\n",
      "video 1/1 (frame 45/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 5 persons, 29.0ms\n",
      "video 1/1 (frame 46/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 4 persons, 27.6ms\n",
      "video 1/1 (frame 47/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 26.5ms\n",
      "video 1/1 (frame 48/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 4 persons, 28.7ms\n",
      "video 1/1 (frame 49/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 4 persons, 30.3ms\n",
      "video 1/1 (frame 50/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 4 persons, 29.0ms\n",
      "video 1/1 (frame 51/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 3 persons, 29.0ms\n",
      "video 1/1 (frame 52/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 5 persons, 28.6ms\n",
      "video 1/1 (frame 53/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 5 persons, 27.9ms\n",
      "video 1/1 (frame 54/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 5 persons, 27.1ms\n",
      "video 1/1 (frame 55/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 4 persons, 29.0ms\n",
      "video 1/1 (frame 56/56) D:\\Users\\Legion\\BIA Technologies\\YOLO_8_test\\data\\videos\\input\\12-07-2024.mp4: 384x640 4 persons, 29.1ms\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1mdata\\videos\\output\\12-07-2024_output3\u001B[0m\n",
      "53 labels saved to data\\videos\\output\\12-07-2024_output3\\labels\n",
      "Не найдено видео в результатах. Проверьте вывод YOLO.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:40:40.380435Z",
     "start_time": "2024-06-25T12:40:40.204412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "#get the dimension of the video\n",
    "cap = cv2.VideoCapture('video_path')\n",
    "if cap.isOpened():\n",
    "    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    size = (w, h)\n",
    "    print(size)"
   ],
   "id": "c4065427c5bc6443",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:40:40.845512Z",
     "start_time": "2024-06-25T12:40:40.596359Z"
    }
   },
   "cell_type": "code",
   "source": "out = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), cap.get(cv2.CAP_PROP_FPS), size)",
   "id": "fd9ab3fe17c20cd9",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m out \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mVideoWriter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput.avi\u001B[39m\u001B[38;5;124m\"\u001B[39m, cv2\u001B[38;5;241m.\u001B[39mVideoWriter_fourcc(\u001B[38;5;241m*\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMJPG\u001B[39m\u001B[38;5;124m\"\u001B[39m), cap\u001B[38;5;241m.\u001B[39mget(cv2\u001B[38;5;241m.\u001B[39mCAP_PROP_FPS), \u001B[43msize\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'size' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T10:45:40.512276Z",
     "start_time": "2024-06-25T10:45:39.681900Z"
    }
   },
   "cell_type": "code",
   "source": "!pip freeze\n",
   "id": "fe54ec0ecdcb790e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.1.0\n",
      "anyio==4.4.0\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==2.4.1\n",
      "async-lru==2.0.4\n",
      "attrs==23.2.0\n",
      "Babel==2.15.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==6.1.0\n",
      "certifi==2024.6.2\n",
      "cffi==1.16.0\n",
      "charset-normalizer==3.3.2\n",
      "colorama==0.4.6\n",
      "comm==0.2.2\n",
      "contourpy==1.2.1\n",
      "cvlib==0.2.7\n",
      "cycler==0.12.1\n",
      "debugpy==1.8.1\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "executing==2.0.1\n",
      "fastjsonschema==2.20.0\n",
      "filelock==3.15.3\n",
      "flatbuffers==24.3.25\n",
      "fonttools==4.53.0\n",
      "fqdn==1.5.1\n",
      "fsspec==2024.6.0\n",
      "gitdb==4.0.11\n",
      "GitPython==3.1.43\n",
      "h11==0.14.0\n",
      "httpcore==1.0.5\n",
      "httpx==0.27.0\n",
      "idna==3.7\n",
      "imageio==2.34.2\n",
      "imutils==0.5.4\n",
      "intel-openmp==2021.4.0\n",
      "ipykernel==6.29.4\n",
      "ipython==8.25.0\n",
      "ipywidgets==8.1.3\n",
      "isoduration==20.11.0\n",
      "jax==0.4.30\n",
      "jaxlib==0.4.30\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.4\n",
      "json5==0.9.25\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.22.0\n",
      "jsonschema-specifications==2023.12.1\n",
      "jupyter==1.0.0\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.10.0\n",
      "jupyter-lsp==2.2.5\n",
      "jupyter_client==8.6.2\n",
      "jupyter_core==5.7.2\n",
      "jupyter_server==2.14.1\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.2.2\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.27.2\n",
      "jupyterlab_widgets==3.0.11\n",
      "kiwisolver==1.4.5\n",
      "MarkupSafe==2.1.5\n",
      "matplotlib==3.9.0\n",
      "matplotlib-inline==0.1.7\n",
      "mediapipe==0.10.14\n",
      "mistune==3.0.2\n",
      "mkl==2021.4.0\n",
      "ml-dtypes==0.4.0\n",
      "mpmath==1.3.0\n",
      "nbclient==0.10.0\n",
      "nbconvert==7.16.4\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.3\n",
      "notebook==7.2.1\n",
      "notebook_shim==0.2.4\n",
      "numpy==1.26.4\n",
      "opencv-contrib-python==4.10.0.84\n",
      "opencv-python==4.10.0.84\n",
      "opt-einsum==3.3.0\n",
      "overrides==7.7.0\n",
      "packaging==24.1\n",
      "pandas==2.2.2\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.4\n",
      "pillow==10.3.0\n",
      "platformdirs==4.2.2\n",
      "progressbar==2.5\n",
      "prometheus_client==0.20.0\n",
      "prompt_toolkit==3.0.47\n",
      "protobuf==4.25.3\n",
      "psutil==6.0.0\n",
      "pure-eval==0.2.2\n",
      "py-cpuinfo==9.0.0\n",
      "pycparser==2.22\n",
      "Pygments==2.18.0\n",
      "pyparsing==3.1.2\n",
      "python-dateutil==2.9.0.post0\n",
      "python-json-logger==2.0.7\n",
      "pytz==2024.1\n",
      "pywin32==306\n",
      "pywinpty==2.0.13\n",
      "PyYAML==6.0.1\n",
      "pyzmq==26.0.3\n",
      "qtconsole==5.5.2\n",
      "QtPy==2.4.1\n",
      "referencing==0.35.1\n",
      "requests==2.32.3\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rpds-py==0.18.1\n",
      "scipy==1.13.1\n",
      "seaborn==0.13.2\n",
      "Send2Trash==1.8.3\n",
      "setuptools==70.1.0\n",
      "six==1.16.0\n",
      "smmap==5.0.1\n",
      "sniffio==1.3.1\n",
      "sounddevice==0.4.7\n",
      "soupsieve==2.5\n",
      "stack-data==0.6.3\n",
      "sympy==1.12.1\n",
      "tbb==2021.13.0\n",
      "terminado==0.18.1\n",
      "thop==0.1.1.post2209072238\n",
      "tinycss2==1.3.0\n",
      "torch==2.3.1+cu121\n",
      "torchaudio==2.3.1+cu121\n",
      "torchvision==0.18.1+cu121\n",
      "tornado==6.4.1\n",
      "tqdm==4.66.4\n",
      "traitlets==5.14.3\n",
      "types-python-dateutil==2.9.0.20240316\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.1\n",
      "ultralytics==8.2.41\n",
      "ultralytics-thop==2.0.0\n",
      "uri-template==1.3.0\n",
      "urllib3==2.2.2\n",
      "wcwidth==0.2.13\n",
      "webcolors==24.6.0\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "widgetsnbextension==4.0.11\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T08:18:49.399665Z",
     "start_time": "2024-07-11T08:18:34.579501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8x-pose.pt')\n",
    "\n",
    "def process_video(video_path, output_dir):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Prepare output video writer\n",
    "    out = cv2.VideoWriter(os.path.join(output_dir, 'output_skeleton.mp4'),\n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    \n",
    "    frames_data = []\n",
    "    frame_id = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "        \n",
    "        # Process results and draw skeletons\n",
    "        frame_data = process_results(results, frame, frame_id)\n",
    "        frames_data.append(frame_data)\n",
    "        \n",
    "        # Write frame with skeletons to video\n",
    "        out.write(frame)\n",
    "        \n",
    "        frame_id += 1\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # Write skeleton data to file\n",
    "    write_skeleton_file(os.path.join(output_dir, 'S001C001P001R001A060.skeleton'), frames_data)\n",
    "\n",
    "def process_results(results, frame, frame_id):\n",
    "    frame_data = {\n",
    "        'frame_id': frame_id,\n",
    "        'bodies': []\n",
    "    }\n",
    "    \n",
    "    for person_id, person in enumerate(results[0].keypoints.xy):\n",
    "        body_data = {\n",
    "            'body_id': person_id,\n",
    "            'joints': []\n",
    "        }\n",
    "        \n",
    "        for joint_id, joint in enumerate(person):\n",
    "            x, y = joint\n",
    "            # Add more properties as needed (Z, color, depth, etc.)\n",
    "            joint_data = {\n",
    "                'x': float(x),\n",
    "                'y': float(y),\n",
    "                'z': 0.0,  # Placeholder, adjust as needed\n",
    "                'color_x': 0,  # Placeholder\n",
    "                'color_y': 0,  # Placeholder\n",
    "                'depth': 0,  # Placeholder\n",
    "                'ir': 0,  # Placeholder\n",
    "                'normal_x': 0,  # Placeholder\n",
    "                'normal_y': 0,  # Placeholder\n",
    "                'normal_z': 0,  # Placeholder\n",
    "                'extra': 0  # Placeholder\n",
    "            }\n",
    "            body_data['joints'].append(joint_data)\n",
    "            \n",
    "            # Draw skeleton on frame\n",
    "            cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "        \n",
    "        frame_data['bodies'].append(body_data)\n",
    "        \n",
    "    return frame_data\n",
    "\n",
    "def write_skeleton_file(filename, frames_data):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(f\"{len(frames_data)}\\n\")  # Number of frames\n",
    "        for frame in frames_data:\n",
    "            f.write(f\"{len(frame['bodies'])}\\n\")  # Number of bodies in frame\n",
    "            for body in frame['bodies']:\n",
    "                # Write body data\n",
    "                f.write(f\"{frame['frame_id']} {body['body_id']} 1 1 1 1 0 0 0 2\\n\")\n",
    "                # Write joint data\n",
    "                for joint in body['joints']:\n",
    "                    f.write(f\"{joint['x']} {joint['y']} {joint['z']} {joint['color_x']} {joint['color_y']} \"\n",
    "                            f\"{joint['depth']} {joint['ir']} {joint['normal_x']} {joint['normal_y']} \"\n",
    "                            f\"{joint['normal_z']} {joint['extra']} 2\\n\")\n",
    "\n",
    "# Main execution\n",
    "video_path = \"D:/Users/Legion/BIA Technologies/YOLO_8_test/data/videos/output/25-06-2024_output3/25-06-2024.avi\"\n",
    "output_dir = 'D:/Users/Legion/BIA Technologies/dataset_SGN/output_labels'\n",
    "\n",
    "process_video(video_path, output_dir)"
   ],
   "id": "7429fb576f58a454",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 26.9ms\n",
      "Speed: 1.1ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 30.0ms\n",
      "Speed: 2.2ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 32.9ms\n",
      "Speed: 1.8ms preprocess, 32.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 30.4ms\n",
      "Speed: 1.0ms preprocess, 30.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 29.9ms\n",
      "Speed: 2.0ms preprocess, 29.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 30.8ms\n",
      "Speed: 1.0ms preprocess, 30.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 31.5ms\n",
      "Speed: 1.3ms preprocess, 31.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 31.6ms\n",
      "Speed: 2.0ms preprocess, 31.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 31.0ms\n",
      "Speed: 1.1ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.7ms\n",
      "Speed: 2.0ms preprocess, 32.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 30.0ms\n",
      "Speed: 1.7ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.4ms\n",
      "Speed: 1.0ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 30.8ms\n",
      "Speed: 1.0ms preprocess, 30.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.7ms\n",
      "Speed: 2.0ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 32.0ms\n",
      "Speed: 2.2ms preprocess, 32.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 34.0ms\n",
      "Speed: 1.1ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 30.3ms\n",
      "Speed: 1.0ms preprocess, 30.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 31.8ms\n",
      "Speed: 1.2ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 29.5ms\n",
      "Speed: 4.8ms preprocess, 29.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 30.2ms\n",
      "Speed: 2.0ms preprocess, 30.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.7ms\n",
      "Speed: 1.5ms preprocess, 31.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.5ms\n",
      "Speed: 1.5ms preprocess, 32.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.1ms\n",
      "Speed: 1.5ms preprocess, 32.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 29.5ms\n",
      "Speed: 2.1ms preprocess, 29.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.2ms\n",
      "Speed: 2.4ms preprocess, 31.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 29.0ms\n",
      "Speed: 1.2ms preprocess, 29.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 31.2ms\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 31.7ms\n",
      "Speed: 1.0ms preprocess, 31.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.8ms\n",
      "Speed: 2.4ms preprocess, 32.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 30.3ms\n",
      "Speed: 2.1ms preprocess, 30.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.4ms\n",
      "Speed: 1.0ms preprocess, 32.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 33.3ms\n",
      "Speed: 2.0ms preprocess, 33.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 31.5ms\n",
      "Speed: 1.2ms preprocess, 31.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 31.4ms\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 30.2ms\n",
      "Speed: 0.5ms preprocess, 30.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 31.8ms\n",
      "Speed: 1.0ms preprocess, 31.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 31.8ms\n",
      "Speed: 1.0ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 31.0ms\n",
      "Speed: 1.4ms preprocess, 31.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 33.2ms\n",
      "Speed: 1.3ms preprocess, 33.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 29.4ms\n",
      "Speed: 1.0ms preprocess, 29.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 33.3ms\n",
      "Speed: 1.2ms preprocess, 33.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 30.3ms\n",
      "Speed: 1.0ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.9ms\n",
      "Speed: 1.1ms preprocess, 32.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 33.8ms\n",
      "Speed: 1.2ms preprocess, 33.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 31.1ms\n",
      "Speed: 2.5ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 31.8ms\n",
      "Speed: 1.0ms preprocess, 31.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 33.4ms\n",
      "Speed: 1.0ms preprocess, 33.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 30.6ms\n",
      "Speed: 1.1ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 28.6ms\n",
      "Speed: 1.3ms preprocess, 28.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 29.5ms\n",
      "Speed: 1.6ms preprocess, 29.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.4ms\n",
      "Speed: 1.4ms preprocess, 32.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.1ms\n",
      "Speed: 2.3ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 30.1ms\n",
      "Speed: 2.2ms preprocess, 30.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 30.9ms\n",
      "Speed: 2.6ms preprocess, 30.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 33.1ms\n",
      "Speed: 1.2ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 30.7ms\n",
      "Speed: 2.5ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 30.7ms\n",
      "Speed: 1.5ms preprocess, 30.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.4ms\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 29.0ms\n",
      "Speed: 1.1ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.1ms\n",
      "Speed: 2.0ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.5ms\n",
      "Speed: 1.2ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.0ms\n",
      "Speed: 1.1ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 29.6ms\n",
      "Speed: 1.5ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 30.8ms\n",
      "Speed: 2.0ms preprocess, 30.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 30.2ms\n",
      "Speed: 1.2ms preprocess, 30.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.6ms\n",
      "Speed: 1.4ms preprocess, 32.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 28.8ms\n",
      "Speed: 2.0ms preprocess, 28.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 29.4ms\n",
      "Speed: 1.3ms preprocess, 29.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 29.3ms\n",
      "Speed: 2.3ms preprocess, 29.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 29.5ms\n",
      "Speed: 2.5ms preprocess, 29.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.3ms\n",
      "Speed: 1.2ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.1ms\n",
      "Speed: 2.1ms preprocess, 32.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 30.5ms\n",
      "Speed: 2.4ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 34.6ms\n",
      "Speed: 1.4ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 33.1ms\n",
      "Speed: 2.0ms preprocess, 33.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.3ms\n",
      "Speed: 2.0ms preprocess, 31.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.3ms\n",
      "Speed: 1.4ms preprocess, 31.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 29.7ms\n",
      "Speed: 2.3ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 30.1ms\n",
      "Speed: 2.1ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.3ms\n",
      "Speed: 2.5ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 34.0ms\n",
      "Speed: 2.2ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 29.6ms\n",
      "Speed: 1.2ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 33.4ms\n",
      "Speed: 1.0ms preprocess, 33.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.1ms\n",
      "Speed: 2.3ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 30.5ms\n",
      "Speed: 1.4ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 29.4ms\n",
      "Speed: 1.3ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.7ms\n",
      "Speed: 2.1ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 29.3ms\n",
      "Speed: 1.0ms preprocess, 29.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.7ms\n",
      "Speed: 2.7ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 28.7ms\n",
      "Speed: 1.4ms preprocess, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.0ms\n",
      "Speed: 2.4ms preprocess, 31.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.9ms\n",
      "Speed: 1.6ms preprocess, 31.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 29.3ms\n",
      "Speed: 2.6ms preprocess, 29.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 29.6ms\n",
      "Speed: 2.3ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 33.8ms\n",
      "Speed: 1.0ms preprocess, 33.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 29.1ms\n",
      "Speed: 2.5ms preprocess, 29.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.0ms\n",
      "Speed: 2.3ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.5ms\n",
      "Speed: 1.1ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.4ms\n",
      "Speed: 2.0ms preprocess, 33.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.4ms\n",
      "Speed: 1.0ms preprocess, 32.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.3ms\n",
      "Speed: 1.2ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.0ms\n",
      "Speed: 2.1ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 32.4ms\n",
      "Speed: 1.5ms preprocess, 32.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.8ms\n",
      "Speed: 1.3ms preprocess, 30.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 30.8ms\n",
      "Speed: 1.2ms preprocess, 30.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 31.7ms\n",
      "Speed: 1.0ms preprocess, 31.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.1ms\n",
      "Speed: 2.2ms preprocess, 32.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.7ms\n",
      "Speed: 2.1ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.7ms\n",
      "Speed: 2.1ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 29.8ms\n",
      "Speed: 2.2ms preprocess, 29.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.7ms\n",
      "Speed: 1.7ms preprocess, 32.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.8ms\n",
      "Speed: 1.0ms preprocess, 32.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 34.3ms\n",
      "Speed: 1.1ms preprocess, 34.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 32.3ms\n",
      "Speed: 1.0ms preprocess, 32.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 31.7ms\n",
      "Speed: 1.0ms preprocess, 31.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.2ms\n",
      "Speed: 1.4ms preprocess, 32.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.3ms\n",
      "Speed: 2.0ms preprocess, 31.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.1ms\n",
      "Speed: 2.0ms preprocess, 33.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 33.9ms\n",
      "Speed: 1.0ms preprocess, 33.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 29.4ms\n",
      "Speed: 1.6ms preprocess, 29.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 33.7ms\n",
      "Speed: 1.2ms preprocess, 33.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 30.7ms\n",
      "Speed: 2.0ms preprocess, 30.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.3ms\n",
      "Speed: 1.0ms preprocess, 31.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 29.7ms\n",
      "Speed: 1.0ms preprocess, 29.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.3ms\n",
      "Speed: 1.0ms preprocess, 34.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.7ms\n",
      "Speed: 1.5ms preprocess, 32.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.4ms\n",
      "Speed: 2.4ms preprocess, 31.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.1ms\n",
      "Speed: 3.0ms preprocess, 32.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 30.3ms\n",
      "Speed: 2.0ms preprocess, 30.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.9ms\n",
      "Speed: 2.0ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.5ms\n",
      "Speed: 1.2ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 30.4ms\n",
      "Speed: 1.0ms preprocess, 30.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.3ms\n",
      "Speed: 1.5ms preprocess, 32.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.0ms\n",
      "Speed: 1.2ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.2ms\n",
      "Speed: 1.0ms preprocess, 33.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 30.0ms\n",
      "Speed: 2.2ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.3ms\n",
      "Speed: 4.2ms preprocess, 30.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.0ms\n",
      "Speed: 2.2ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 29.2ms\n",
      "Speed: 2.1ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 32.2ms\n",
      "Speed: 2.2ms preprocess, 32.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.1ms\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 29.4ms\n",
      "Speed: 2.3ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.2ms\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8641398cbaf776c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
